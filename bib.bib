
@misc{hafner2018learning,
	title={Learning Latent Dynamics for Planning from Pixels},
	author={Danijar Hafner and Timothy Lillicrap and Ian Fischer and Ruben Villegas and David Ha and Honglak Lee and James Davidson},
	year={2018},
	eprint={1811.04551},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}
@article{defreitas,
	author = {Freitas, J. F. G. de and Niranjan, M. and Gee, A. H. and Doucet, A.},
	title = {Sequential Monte Carlo Methods to Train Neural Network Models},
	journal = {Neural Computation},
	volume = {12},
	number = {4},
	pages = {955-993},
	year = {2000},
	doi = {10.1162/089976600300015664},
	
	URL = { 
		https://doi.org/10.1162/089976600300015664
		
	},
	eprint = { 
		https://doi.org/10.1162/089976600300015664
		
	}
	,
	abstract = { We discuss a novel strategy for training neural networks using sequential Monte Carlo algorithms and propose a new hybrid gradient descent/sampling importance resampling algorithm (HySIR). In terms of computational time and accuracy, the hybrid SIR is a clear improvement over conventional sequential Monte Carlo techniques. The new algorithm may be viewed as a global optimization strategy that allows us to learn the probability distributions of the network weights and outputs in a sequential framework. It is well suited to applications involving on-line, nonlinear, and nongaussian signal processing. We show how the new algorithm outperforms extended Kalman filter training on several problems. In particular, we address the problem of pricing option contracts, traded in financial markets. In this context, we are able to estimate the one-step-ahead probability density functions of the options prices. }
}

@unpublished{feydy:hal-01827184,
	TITLE = {{Global divergences between measures: from Hausdorff distance to Optimal Transport}},
	AUTHOR = {Feydy, Jean and Trouv{\'e}, Alain},
	URL = {https://hal.archives-ouvertes.fr/hal-01827184},
	NOTE = {working paper or preprint},
	YEAR = {2018},
	MONTH = Aug,
	PDF = {https://hal.archives-ouvertes.fr/hal-01827184/file/ShapeMI_2018_camera_ready.pdf},
	HAL_ID = {hal-01827184},
	HAL_VERSION = {v2},
}

@misc{reich2012nonparametric,
	title={A non-parametric ensemble transform method for Bayesian inference},
	author={Sebastian Reich},
	year={2012},
	eprint={1210.0375},
	archivePrefix={arXiv},
	primaryClass={math.NA}
}



@misc{cuturi2013sinkhorn,
	title={Sinkhorn Distances: Lightspeed Computation of Optimal Transportation Distances},
	author={Marco Cuturi},
	year={2013},
	eprint={1306.0895},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@misc{blondel2017smooth,
	title={Smooth and Sparse Optimal Transport},
	author={Mathieu Blondel and Vivien Seguy and Antoine Rolet},
	year={2017},
	eprint={1710.06276},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@misc{genevay2017learning,
	title={Learning Generative Models with Sinkhorn Divergences},
	author={Aude Genevay and Gabriel Peyr\'e and Marco Cuturi},
	year={2017},
	eprint={1706.00292},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@article{Cuturi_2018,
	title={Semidual Regularized Optimal Transport},
	volume={60},
	ISSN={1095-7200},
	url={http://dx.doi.org/10.1137/18M1208654},
	DOI={10.1137/18m1208654},
	number={4},
	journal={SIAM Review},
	publisher={Society for Industrial & Applied Mathematics (SIAM)},
	author={Cuturi, Marco and Peyré, Gabriel},
	year={2018},
	month={Jan},
	pages={941–965}
}

@article{El_Moselhy_2012,
	title={Bayesian inference with optimal maps},
	volume={231},
	ISSN={0021-9991},
	url={http://dx.doi.org/10.1016/j.jcp.2012.07.022},
	DOI={10.1016/j.jcp.2012.07.022},
	number={23},
	journal={Journal of Computational Physics},
	publisher={Elsevier BV},
	author={El Moselhy, Tarek A. and Marzouk, Youssef M.},
	year={2012},
	month={Oct},
	pages={7815–7850}
}

@misc{feydy:interpolating,
	author = {Jean Feydy and Thibault Séjourné and François-Xavier Vialard and Shun-ichi Amari and Alain Trouvé and Gabriel Peyré},
	title = {Interpolating between Optimal Transport and MMD using Sinkhorn Divergences},
	date = {2018},
    eprint={1810.08278},
	archivePrefix={arXiv},
	primaryClass={math.ST}
}
